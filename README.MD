# ğŸ§  Sign Language Detection using Action Recognition

> A deep learning project that uses **MediaPipe Holistic**, **LSTM Neural Networks**, and **Action Recognition** to detect and classify American Sign Language (ASL) gestures like `Hello`, `Thank You`, and `I Love You` in real-time from webcam input.

---

## ğŸš€ Project Highlights

- ğŸ” **Real-time Pose, Hand & Face Tracking** using MediaPipe Holistic.
- ğŸ¤– **Action Classification** via LSTM-based neural networks trained on sequential keypoints.
- ğŸ“ˆ Achieved high accuracy on custom dataset with 3-class gesture recognition.
- ğŸ’¾ Organized training pipeline with NumPy-based keypoint extraction.
- ğŸ¨ Live prediction visualization using OpenCV.

---

## ğŸ›  Tech Stack

| Tool/Library        | Purpose                                 |
|---------------------|-----------------------------------------|
| `MediaPipe`         | Real-time holistic human pose tracking  |
| `OpenCV`            | Image capture and display               |
| `TensorFlow/Keras`  | LSTM model training and prediction      |
| `NumPy`             | Feature vector generation               |
| `Matplotlib`        | Data visualization                      |
| `Scikit-learn`      | Model evaluation and preprocessing      |

---


